{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dropout,Flatten,Conv2D,MaxPooling2D,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rotation_range=30,width_shift_range=0.1,height_shift_range=0.1,rescale=1/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 19398 images belonging to 2 classes.\n"
    },
    {
     "data": {
      "text/plain": "<keras_preprocessing.image.DirectoryIterator at 0x1a7a42ad828>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen.flow_from_directory(r'D:\\Programs\\Python\\DATA\\Cell_Images\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (80,80,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(80,80,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(80,80,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(80,80,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 19398 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "batch_size=16\n",
    "train_image_gen = image_gen.flow_from_directory(r'D:\\Programs\\Python\\DATA\\Cell_Images\\train',target_size=input_shape[:2],batch_size=batch_size,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 8160 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "test_image_gen = image_gen.flow_from_directory(r'D:\\Programs\\Python\\DATA\\Cell_Images\\test',target_size=input_shape[:2],batch_size=batch_size,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/20\n150/150 [==============================] - 172s 1s/step - loss: 0.6920 - acc: 0.5312 - val_loss: 0.6897 - val_acc: 0.5924\nEpoch 2/20\n150/150 [==============================] - 93s 620ms/step - loss: 0.6926 - acc: 0.5290 - val_loss: 0.6917 - val_acc: 0.5286\nEpoch 3/20\n150/150 [==============================] - 89s 593ms/step - loss: 0.6923 - acc: 0.5242 - val_loss: 0.6889 - val_acc: 0.5729\nEpoch 4/20\n150/150 [==============================] - 85s 564ms/step - loss: 0.5678 - acc: 0.7308 - val_loss: 0.4120 - val_acc: 0.8292\nEpoch 5/20\n150/150 [==============================] - 85s 566ms/step - loss: 0.3583 - acc: 0.8742 - val_loss: 0.2704 - val_acc: 0.8975\nEpoch 6/20\n150/150 [==============================] - 93s 620ms/step - loss: 0.2425 - acc: 0.9179 - val_loss: 0.2554 - val_acc: 0.8917\nEpoch 7/20\n150/150 [==============================] - 79s 530ms/step - loss: 0.2556 - acc: 0.9083 - val_loss: 0.2163 - val_acc: 0.9310\nEpoch 8/20\n150/150 [==============================] - 84s 560ms/step - loss: 0.2370 - acc: 0.9200 - val_loss: 0.2341 - val_acc: 0.9249\nEpoch 9/20\n150/150 [==============================] - 52s 347ms/step - loss: 0.2035 - acc: 0.9304 - val_loss: 0.2229 - val_acc: 0.9276\nEpoch 10/20\n150/150 [==============================] - 51s 340ms/step - loss: 0.2161 - acc: 0.9329 - val_loss: 0.2020 - val_acc: 0.9359\nEpoch 11/20\n150/150 [==============================] - 66s 438ms/step - loss: 0.2173 - acc: 0.9326 - val_loss: 0.1903 - val_acc: 0.9422\nEpoch 12/20\n150/150 [==============================] - 63s 417ms/step - loss: 0.2054 - acc: 0.9371 - val_loss: 0.2070 - val_acc: 0.9314\nEpoch 13/20\n150/150 [==============================] - 62s 415ms/step - loss: 0.1793 - acc: 0.9383 - val_loss: 0.2026 - val_acc: 0.9375\nEpoch 14/20\n150/150 [==============================] - 60s 400ms/step - loss: 0.1976 - acc: 0.9321 - val_loss: 0.1973 - val_acc: 0.9273\nEpoch 15/20\n150/150 [==============================] - 56s 373ms/step - loss: 0.1903 - acc: 0.9371 - val_loss: 0.1967 - val_acc: 0.9366\nEpoch 16/20\n150/150 [==============================] - 60s 399ms/step - loss: 0.1945 - acc: 0.9417 - val_loss: 0.1917 - val_acc: 0.9379\nEpoch 17/20\n150/150 [==============================] - 58s 388ms/step - loss: 0.1699 - acc: 0.9400 - val_loss: 0.2269 - val_acc: 0.9205\nEpoch 18/20\n150/150 [==============================] - 56s 376ms/step - loss: 0.1970 - acc: 0.9346 - val_loss: 0.1831 - val_acc: 0.9439\nEpoch 19/20\n150/150 [==============================] - 48s 319ms/step - loss: 0.1696 - acc: 0.9437 - val_loss: 0.1993 - val_acc: 0.9386\nEpoch 20/20\n150/150 [==============================] - 51s 342ms/step - loss: 0.1916 - acc: 0.9413 - val_loss: 0.1863 - val_acc: 0.9411\n"
    }
   ],
   "source": [
    "results = model.fit_generator(train_image_gen,epochs=20,steps_per_epoch=150,validation_data=test_image_gen,validation_steps=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    parasite = r'C:\\Users\\coolb\\Desktop\\Y7N9m.png'\n",
    "    p = image.load_img(parasite,target_size=(80,80))\n",
    "    p = image.img_to_array(p)\n",
    "    p = np.expand_dims(p,axis=0)\n",
    "    p = p/255\n",
    "    percentage = model.predict(p)\n",
    "    percentage = 100*percentage\n",
    "    print(\"There are\",percentage[0],\" percent chances that you have malaria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "There are [0.6278218]  percent chances that you have malaria\n"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}